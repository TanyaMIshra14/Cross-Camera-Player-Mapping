{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6daa82bb",
   "metadata": {},
   "source": [
    "# Cross Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb773db1",
   "metadata": {},
   "source": [
    "## Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e77e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a15e4",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc11a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cosine\n",
    "from collections import defaultdict, deque\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fdbbff",
   "metadata": {},
   "source": [
    "## Detect each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PlayerDetection:\n",
    "    bbox: Tuple[int, int, int, int]\n",
    "    confidence: float\n",
    "    frame_id: int\n",
    "    camera_id: str\n",
    "    player_id: Optional[int] = None\n",
    "    features: Optional[np.ndarray] = None\n",
    "    track_id: Optional[int] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0a6f7",
   "metadata": {},
   "source": [
    "## Match Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03ef742",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MatchResult:\n",
    "    tacticam_idx: int\n",
    "    broadcast_idx: int\n",
    "    similarity_score: float\n",
    "    confidence: float\n",
    "    tacticam_id: Optional[int] = None\n",
    "    broadcast_id: Optional[int] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834ef4b7",
   "metadata": {},
   "source": [
    "## Track players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2226fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PlayerTrack:\n",
    "    player_id: int\n",
    "    camera_id: str\n",
    "    feature_history: List[np.ndarray]\n",
    "    bbox_history: List[Tuple[int, int, int, int]]\n",
    "    last_seen_frame: int\n",
    "    confidence_history: List[float]\n",
    "\n",
    "    def get_average_features(self) -> np.ndarray:\n",
    "        if not self.feature_history:\n",
    "            return np.zeros(2048)\n",
    "        return np.mean(self.feature_history, axis=0)\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        bbox: Tuple[int, int, int, int],\n",
    "        features: np.ndarray,\n",
    "        frame_id: int,\n",
    "        confidence: float,\n",
    "    ):\n",
    "        self.bbox_history.append(bbox)\n",
    "        self.feature_history.append(features)\n",
    "        self.confidence_history.append(confidence)\n",
    "        self.last_seen_frame = frame_id\n",
    "        if len(self.feature_history) > 10:\n",
    "            self.feature_history = self.feature_history[-10:]\n",
    "            self.bbox_history = self.bbox_history[-10:]\n",
    "            self.confidence_history = self.confidence_history[-10:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ef1df",
   "metadata": {},
   "source": [
    "## Extract Visual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.backbone = resnet50(weights=\"IMAGENET1K_V1\")\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.eval()\n",
    "            self.device = device\n",
    "            self.backbone.to(self.device)\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "            print(f\" Feature extractor initialized on {self.device}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error initializing feature extractor: {e}\")\n",
    "            raise\n",
    "\n",
    "    def extract_features(self, image_patch: np.ndarray) -> np.ndarray:\n",
    "        if image_patch is None or image_patch.size == 0:\n",
    "            return np.zeros(2048)\n",
    "        try:\n",
    "            if image_patch.shape[0] < 32 or image_patch.shape[1] < 32:\n",
    "                return np.zeros(2048)\n",
    "            if len(image_patch.shape) == 3 and image_patch.shape[2] == 3:\n",
    "                image_patch = cv2.cvtColor(image_patch, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                return np.zeros(2048)\n",
    "            tensor = self.transform(image_patch).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                features = self.backbone(tensor)\n",
    "            return features.cpu().numpy().flatten()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Feature extraction failed: {e}\")\n",
    "            return np.zeros(2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e878e",
   "metadata": {},
   "source": [
    "## Track players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerTracker:\n",
    "    def __init__(self, max_disappeared: int = 5):\n",
    "        self.tracks = {}\n",
    "        self.next_id = 1\n",
    "        self.max_disappeared = max_disappeared\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        detections: List[PlayerDetection],\n",
    "        frame_id: int,\n",
    "        frame: np.ndarray,\n",
    "        camera_id: str,\n",
    "        feature_extractor,\n",
    "    ) -> List[PlayerDetection]:\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = det.bbox\n",
    "            h, w = frame.shape[:2]\n",
    "            x1, y1 = max(0, x1), max(0, y1)\n",
    "            x2, y2 = min(w, x2), min(h, y2)\n",
    "            if x2 > x1 and y2 > y1:\n",
    "                patch = frame[y1:y2, x1:x2]\n",
    "                det.features = feature_extractor.extract_features(patch)\n",
    "            else:\n",
    "                det.features = np.zeros(2048)\n",
    "        if not self.tracks:\n",
    "            for i, det in enumerate(detections):\n",
    "                track_id = self.next_id\n",
    "                self.next_id += 1\n",
    "                self.tracks[track_id] = PlayerTrack(\n",
    "                    player_id=track_id,\n",
    "                    camera_id=camera_id,\n",
    "                    feature_history=[det.features],\n",
    "                    bbox_history=[det.bbox],\n",
    "                    last_seen_frame=frame_id,\n",
    "                    confidence_history=[det.confidence],\n",
    "                )\n",
    "                det.track_id = track_id\n",
    "                det.player_id = track_id\n",
    "            return detections\n",
    "        active_tracks = {\n",
    "            tid: track\n",
    "            for tid, track in self.tracks.items()\n",
    "            if frame_id - track.last_seen_frame <= self.max_disappeared\n",
    "        }\n",
    "        if not active_tracks:\n",
    "            for det in detections:\n",
    "                track_id = self.next_id\n",
    "                self.next_id += 1\n",
    "                self.tracks[track_id] = PlayerTrack(\n",
    "                    player_id=track_id,\n",
    "                    camera_id=camera_id,\n",
    "                    feature_history=[det.features],\n",
    "                    bbox_history=[det.bbox],\n",
    "                    last_seen_frame=frame_id,\n",
    "                    confidence_history=[det.confidence],\n",
    "                )\n",
    "                det.track_id = track_id\n",
    "                det.player_id = track_id\n",
    "            return detections\n",
    "        track_ids = list(active_tracks.keys())\n",
    "        similarity_matrix = np.zeros((len(detections), len(track_ids)))\n",
    "        for i, det in enumerate(detections):\n",
    "            for j, track_id in enumerate(track_ids):\n",
    "                track = active_tracks[track_id]\n",
    "                avg_features = track.get_average_features()\n",
    "                if (\n",
    "                    np.linalg.norm(det.features) > 0\n",
    "                    and np.linalg.norm(avg_features) > 0\n",
    "                ):\n",
    "                    similarity = np.dot(det.features, avg_features) / (\n",
    "                        np.linalg.norm(det.features) * np.linalg.norm(avg_features)\n",
    "                    )\n",
    "                    similarity_matrix[i, j] = max(0, similarity)\n",
    "                else:\n",
    "                    similarity_matrix[i, j] = 0\n",
    "        if similarity_matrix.size > 0:\n",
    "            cost_matrix = 1.0 - similarity_matrix\n",
    "            det_indices, track_indices = linear_sum_assignment(cost_matrix)\n",
    "            assigned_dets = set()\n",
    "            assigned_tracks = set()\n",
    "            for det_idx, track_idx in zip(det_indices, track_indices):\n",
    "                if similarity_matrix[det_idx, track_idx] > 0.3:\n",
    "                    track_id = track_ids[track_idx]\n",
    "                    track = active_tracks[track_id]\n",
    "                    det = detections[det_idx]\n",
    "                    track.update(det.bbox, det.features, frame_id, det.confidence)\n",
    "                    det.track_id = track_id\n",
    "                    det.player_id = track_id\n",
    "                    assigned_dets.add(det_idx)\n",
    "                    assigned_tracks.add(track_id)\n",
    "            for i, det in enumerate(detections):\n",
    "                if i not in assigned_dets:\n",
    "                    track_id = self.next_id\n",
    "                    self.next_id += 1\n",
    "                    self.tracks[track_id] = PlayerTrack(\n",
    "                        player_id=track_id,\n",
    "                        camera_id=camera_id,\n",
    "                        feature_history=[det.features],\n",
    "                        bbox_history=[det.bbox],\n",
    "                        last_seen_frame=frame_id,\n",
    "                        confidence_history=[det.confidence],\n",
    "                    )\n",
    "                    det.track_id = track_id\n",
    "                    det.player_id = track_id\n",
    "        return detections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c883c881",
   "metadata": {},
   "source": [
    "## Match players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerMatcher:\n",
    "    def __init__(self, similarity_threshold: float = 0.4):\n",
    "        self.feature_extractor = VisualFeatureExtractor()\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.trackers = {\"tacticam\": PlayerTracker(), \"broadcast\": PlayerTracker()}\n",
    "        self.cross_camera_matches = {}\n",
    "        self.global_id_counter = 1000\n",
    "        print(f\" Player matcher initialized (threshold: {similarity_threshold})\")\n",
    "\n",
    "    def calculate_similarity(\n",
    "        self, features1: np.ndarray, features2: np.ndarray\n",
    "    ) -> float:\n",
    "        if len(features1) == 0 or len(features2) == 0:\n",
    "            return 0.0\n",
    "        try:\n",
    "            norm1 = np.linalg.norm(features1)\n",
    "            norm2 = np.linalg.norm(features2)\n",
    "            if norm1 == 0 or norm2 == 0:\n",
    "                return 0.0\n",
    "            similarity = np.dot(features1, features2) / (norm1 * norm2)\n",
    "            return max(0.0, min(1.0, similarity))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    def match_players(\n",
    "        self,\n",
    "        tacticam_detections: List[PlayerDetection],\n",
    "        broadcast_detections: List[PlayerDetection],\n",
    "        tacticam_frame: np.ndarray,\n",
    "        broadcast_frame: np.ndarray,\n",
    "        frame_id: int,\n",
    "    ) -> List[MatchResult]:\n",
    "        tacticam_tracked = self.trackers[\"tacticam\"].update(\n",
    "            tacticam_detections,\n",
    "            frame_id,\n",
    "            tacticam_frame,\n",
    "            \"tacticam\",\n",
    "            self.feature_extractor,\n",
    "        )\n",
    "        broadcast_tracked = self.trackers[\"broadcast\"].update(\n",
    "            broadcast_detections,\n",
    "            frame_id,\n",
    "            broadcast_frame,\n",
    "            \"broadcast\",\n",
    "            self.feature_extractor,\n",
    "        )\n",
    "        if not tacticam_tracked or not broadcast_tracked:\n",
    "            return []\n",
    "        matches = []\n",
    "        similarity_matrix = np.zeros((len(tacticam_tracked), len(broadcast_tracked)))\n",
    "        for i, tac_det in enumerate(tacticam_tracked):\n",
    "            for j, broad_det in enumerate(broadcast_tracked):\n",
    "                if tac_det.features is not None and broad_det.features is not None:\n",
    "                    similarity = self.calculate_similarity(\n",
    "                        tac_det.features, broad_det.features\n",
    "                    )\n",
    "                    similarity_matrix[i, j] = similarity\n",
    "        if similarity_matrix.size > 0:\n",
    "            cost_matrix = 1.0 - similarity_matrix\n",
    "            tac_indices, broad_indices = linear_sum_assignment(cost_matrix)\n",
    "            for tac_idx, broad_idx in zip(tac_indices, broad_indices):\n",
    "                score = similarity_matrix[tac_idx, broad_idx]\n",
    "                if score >= self.similarity_threshold:\n",
    "                    tac_det = tacticam_tracked[tac_idx]\n",
    "                    broad_det = broadcast_tracked[broad_idx]\n",
    "                    if tac_det.track_id in self.cross_camera_matches:\n",
    "                        global_id = self.cross_camera_matches[tac_det.track_id]\n",
    "                        broad_det.player_id = global_id\n",
    "                        tac_det.player_id = global_id\n",
    "                    elif broad_det.track_id in [\n",
    "                        v for v in self.cross_camera_matches.values()\n",
    "                    ]:\n",
    "                        for tac_id, broad_id in self.cross_camera_matches.items():\n",
    "                            if broad_id == broad_det.track_id:\n",
    "                                tac_det.player_id = broad_id\n",
    "                                broad_det.player_id = broad_id\n",
    "                                break\n",
    "                    else:\n",
    "                        global_id = self.global_id_counter\n",
    "                        self.global_id_counter += 1\n",
    "                        self.cross_camera_matches[tac_det.track_id] = global_id\n",
    "                        tac_det.player_id = global_id\n",
    "                        broad_det.player_id = global_id\n",
    "                    matches.append(\n",
    "                        MatchResult(\n",
    "                            tacticam_idx=tac_idx,\n",
    "                            broadcast_idx=broad_idx,\n",
    "                            similarity_score=score,\n",
    "                            confidence=score,\n",
    "                            tacticam_id=tac_det.player_id,\n",
    "                            broadcast_id=broad_det.player_id,\n",
    "                        )\n",
    "                    )\n",
    "        return matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a42b31",
   "metadata": {},
   "source": [
    "## Player Reidentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerReIDSystem:\n",
    "    def __init__(self, model_path: str = \"yolov8n.pt\"):\n",
    "        try:\n",
    "            self.detector = YOLO(model_path)\n",
    "            self.matcher = PlayerMatcher()\n",
    "            print(\" Player Re-ID System initialized successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error initializing system: {e}\")\n",
    "            raise\n",
    "\n",
    "    def detect_players(\n",
    "        self, frame: np.ndarray, camera_id: str, frame_id: int\n",
    "    ) -> List[PlayerDetection]:\n",
    "        try:\n",
    "            results = self.detector(frame, verbose=False)\n",
    "            detections = []\n",
    "            for result in results:\n",
    "                if result.boxes is not None:\n",
    "                    for box in result.boxes:\n",
    "                        if int(box.cls[0]) == 0:\n",
    "                            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "                            confidence = float(box.conf[0].cpu().numpy())\n",
    "                            if x2 > x1 and y2 > y1 and confidence > 0.4:\n",
    "                                width = x2 - x1\n",
    "                                height = y2 - y1\n",
    "                                if width > 30 and height > 50:\n",
    "                                    detections.append(\n",
    "                                        PlayerDetection(\n",
    "                                            bbox=(x1, y1, x2, y2),\n",
    "                                            confidence=confidence,\n",
    "                                            frame_id=frame_id,\n",
    "                                            camera_id=camera_id,\n",
    "                                        )\n",
    "                                    )\n",
    "            return detections\n",
    "        except Exception as e:\n",
    "            print(f\" Error in player detection frame {frame_id}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def process_frame_pair(\n",
    "        self, tac_frame: np.ndarray, broad_frame: np.ndarray, frame_id: int\n",
    "    ) -> Dict:\n",
    "        try:\n",
    "            tac_dets = self.detect_players(tac_frame, \"tacticam\", frame_id)\n",
    "            broad_dets = self.detect_players(broad_frame, \"broadcast\", frame_id)\n",
    "            matches = self.matcher.match_players(\n",
    "                tac_dets, broad_dets, tac_frame, broad_frame, frame_id\n",
    "            )\n",
    "            return {\n",
    "                \"frame_id\": frame_id,\n",
    "                \"tacticam_detections\": tac_dets,\n",
    "                \"broadcast_detections\": broad_dets,\n",
    "                \"matches\": matches,\n",
    "                \"num_matches\": len(matches),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\" Error processing frame pair {frame_id}: {e}\")\n",
    "            return {\n",
    "                \"frame_id\": frame_id,\n",
    "                \"tacticam_detections\": [],\n",
    "                \"broadcast_detections\": [],\n",
    "                \"matches\": [],\n",
    "                \"num_matches\": 0,\n",
    "            }\n",
    "\n",
    "    def visualize_results(\n",
    "        self, tac_frame: np.ndarray, broad_frame: np.ndarray, result: Dict\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        try:\n",
    "            tac_vis = tac_frame.copy()\n",
    "            broad_vis = broad_frame.copy()\n",
    "            colors = [\n",
    "                (0, 255, 0),\n",
    "                (255, 0, 0),\n",
    "                (0, 0, 255),\n",
    "                (255, 255, 0),\n",
    "                (255, 0, 255),\n",
    "                (0, 255, 255),\n",
    "                (255, 165, 0),\n",
    "                (128, 0, 128),\n",
    "                (255, 192, 203),\n",
    "                (0, 128, 128),\n",
    "                (128, 128, 0),\n",
    "                (128, 0, 0),\n",
    "            ]\n",
    "            for det in result[\"tacticam_detections\"]:\n",
    "                if det.player_id is not None:\n",
    "                    color = colors[det.player_id % len(colors)]\n",
    "                    x1, y1, x2, y2 = det.bbox\n",
    "                    cv2.rectangle(tac_vis, (x1, y1), (x2, y2), color, 3)\n",
    "                    label = f\"ID:{det.player_id}\"\n",
    "                    label_size = cv2.getTextSize(\n",
    "                        label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2\n",
    "                    )[0]\n",
    "                    cv2.rectangle(\n",
    "                        tac_vis, (x1, y1 - 25), (x1 + label_size[0] + 10, y1), color, -1\n",
    "                    )\n",
    "                    cv2.putText(\n",
    "                        tac_vis,\n",
    "                        label,\n",
    "                        (x1 + 5, y1 - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7,\n",
    "                        (255, 255, 255),\n",
    "                        2,\n",
    "                    )\n",
    "            for det in result[\"broadcast_detections\"]:\n",
    "                if det.player_id is not None:\n",
    "                    color = colors[det.player_id % len(colors)]\n",
    "                    x1, y1, x2, y2 = det.bbox\n",
    "                    cv2.rectangle(broad_vis, (x1, y1), (x2, y2), color, 3)\n",
    "                    label = f\"ID:{det.player_id}\"\n",
    "                    label_size = cv2.getTextSize(\n",
    "                        label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2\n",
    "                    )[0]\n",
    "                    cv2.rectangle(\n",
    "                        broad_vis,\n",
    "                        (x1, y1 - 25),\n",
    "                        (x1 + label_size[0] + 10, y1),\n",
    "                        color,\n",
    "                        -1,\n",
    "                    )\n",
    "                    cv2.putText(\n",
    "                        broad_vis,\n",
    "                        label,\n",
    "                        (x1 + 5, y1 - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7,\n",
    "                        (255, 255, 255),\n",
    "                        2,\n",
    "                    )\n",
    "            info_text = f\"Tacticam - Frame {result['frame_id']} - Matches: {result['num_matches']}\"\n",
    "            cv2.rectangle(tac_vis, (5, 5), (600, 40), (0, 0, 0), -1)\n",
    "            cv2.putText(\n",
    "                tac_vis,\n",
    "                info_text,\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "            )\n",
    "            info_text = f\"Broadcast - Frame {result['frame_id']} - Matches: {result['num_matches']}\"\n",
    "            cv2.rectangle(broad_vis, (5, 5), (600, 40), (0, 0, 0), -1)\n",
    "            cv2.putText(\n",
    "                broad_vis,\n",
    "                info_text,\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "            )\n",
    "            return tac_vis, broad_vis\n",
    "        except Exception as e:\n",
    "            print(f\" Error in visualization: {e}\")\n",
    "            return tac_frame, broad_frame\n",
    "\n",
    "    def process_videos(\n",
    "        self,\n",
    "        tac_path: str,\n",
    "        broad_path: str,\n",
    "        output_path: str = None,\n",
    "        max_frames: int = None,\n",
    "    ) -> Dict:\n",
    "        print(f\" Tacticam: {tac_path}\")\n",
    "        print(f\" Broadcast: {broad_path}\")\n",
    "        if not os.path.exists(tac_path):\n",
    "            raise FileNotFoundError(f\"Tacticam video not found: {tac_path}\")\n",
    "        if not os.path.exists(broad_path):\n",
    "            raise FileNotFoundError(f\"Broadcast video not found: {broad_path}\")\n",
    "        tac_cap = cv2.VideoCapture(tac_path)\n",
    "        broad_cap = cv2.VideoCapture(broad_path)\n",
    "        if not tac_cap.isOpened():\n",
    "            raise ValueError(f\" Could not open tacticam video: {tac_path}\")\n",
    "        if not broad_cap.isOpened():\n",
    "            raise ValueError(f\" Could not open broadcast video: {broad_path}\")\n",
    "        try:\n",
    "            fps = int(tac_cap.get(cv2.CAP_PROP_FPS))\n",
    "            width = int(tac_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(tac_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            total_frames = int(tac_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "            print(f\" Video properties: {width}x{height} @ {fps}fps\")\n",
    "            print(f\" Total frames available: {total_frames}\")\n",
    "            if max_frames:\n",
    "                print(f\" Processing limited to: {max_frames} frames\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error getting video properties: {e}\")\n",
    "            fps, width, height = 30, 640, 480\n",
    "        out = None\n",
    "        if output_path:\n",
    "            try:\n",
    "                fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "                out = cv2.VideoWriter(output_path, fourcc, fps, (width * 2, height))\n",
    "                if not out.isOpened():\n",
    "                    print(f\"Could not create output video at {output_path}\")\n",
    "                    out = None\n",
    "                else:\n",
    "                    print(f\"Output video will be saved to: {output_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating output video: {e}\")\n",
    "                out = None\n",
    "        results = []\n",
    "        frame_id = 0\n",
    "        successful_frames = 0\n",
    "        total_players_detected = set()\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            while True:\n",
    "                if max_frames and frame_id >= max_frames:\n",
    "                    break\n",
    "                ret1, tac_frame = tac_cap.read()\n",
    "                ret2, broad_frame = broad_cap.read()\n",
    "                if not ret1 or not ret2:\n",
    "                    break\n",
    "                result = self.process_frame_pair(tac_frame, broad_frame, frame_id)\n",
    "                results.append(result)\n",
    "                if result[\"num_matches\"] > 0:\n",
    "                    successful_frames += 1\n",
    "                for det in result[\"tacticam_detections\"]:\n",
    "                    if det.player_id is not None:\n",
    "                        total_players_detected.add(det.player_id)\n",
    "                for det in result[\"broadcast_detections\"]:\n",
    "                    if det.player_id is not None:\n",
    "                        total_players_detected.add(det.player_id)\n",
    "                if out is not None:\n",
    "                    try:\n",
    "                        tac_vis, broad_vis = self.visualize_results(\n",
    "                            tac_frame, broad_frame, result\n",
    "                        )\n",
    "                        if tac_vis.shape != broad_vis.shape:\n",
    "                            broad_vis = cv2.resize(\n",
    "                                broad_vis, (tac_vis.shape[1], tac_vis.shape[0])\n",
    "                            )\n",
    "                        combined = np.hstack([tac_vis, broad_vis])\n",
    "                        out.write(combined)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error writing frame {frame_id}: {e}\")\n",
    "                frame_id += 1\n",
    "                if frame_id % 30 == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    fps_processing = frame_id / elapsed\n",
    "                    print(\n",
    "                        f\"Frame {frame_id} | Matches: {successful_frames} | Players: {len(total_players_detected)} | Speed: {fps_processing:.1f} fps\"\n",
    "                    )\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n Processing interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error during processing: {e}\")\n",
    "        finally:\n",
    "            tac_cap.release()\n",
    "            broad_cap.release()\n",
    "            if out is not None:\n",
    "                out.release()\n",
    "        processing_time = time.time() - start_time\n",
    "        print(f\"Frames processed: {frame_id}\")\n",
    "        print(f\"Total time: {processing_time:.1f} seconds\")\n",
    "        print(f\"Processed {frame_id} frames with matches in {successful_frames} frames\")\n",
    "        print(f\"Total unique players detected: {len(total_players_detected)}\")\n",
    "        total_matches = sum(r[\"num_matches\"] for r in results)\n",
    "        return {\n",
    "            \"total_frames\": frame_id,\n",
    "            \"successful_frames\": successful_frames,\n",
    "            \"total_matches\": total_matches,\n",
    "            \"unique_players\": len(total_players_detected),\n",
    "            \"processing_time\": processing_time,\n",
    "            \"results\": results,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd3a457",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5935fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results: Dict, json_path: str = \"results.json\"):\n",
    "    try:\n",
    "        print(f\"Saving results to {json_path}\")\n",
    "\n",
    "        serializable = []\n",
    "        for result in results[\"results\"]:\n",
    "            ser_result = {\n",
    "                \"frame_id\": result[\"frame_id\"],\n",
    "                \"num_matches\": result[\"num_matches\"],\n",
    "                \"tacticam_detections\": [\n",
    "                    {\n",
    "                        \"bbox\": det.bbox,\n",
    "                        \"confidence\": det.confidence,\n",
    "                        \"player_id\": det.player_id,\n",
    "                        \"track_id\": det.track_id,\n",
    "                        \"camera_id\": det.camera_id,\n",
    "                    }\n",
    "                    for det in result[\"tacticam_detections\"]\n",
    "                ],\n",
    "                \"broadcast_detections\": [\n",
    "                    {\n",
    "                        \"bbox\": det.bbox,\n",
    "                        \"confidence\": det.confidence,\n",
    "                        \"player_id\": det.player_id,\n",
    "                        \"track_id\": det.track_id,\n",
    "                        \"camera_id\": det.camera_id,\n",
    "                    }\n",
    "                    for det in result[\"broadcast_detections\"]\n",
    "                ],\n",
    "                \"matches\": [\n",
    "                    {\n",
    "                        \"tacticam_idx\": m.tacticam_idx,\n",
    "                        \"broadcast_idx\": m.broadcast_idx,\n",
    "                        \"similarity\": m.similarity_score,\n",
    "                        \"confidence\": m.confidence,\n",
    "                        \"tacticam_id\": m.tacticam_id,\n",
    "                        \"broadcast_id\": m.broadcast_id,\n",
    "                    }\n",
    "                    for m in result[\"matches\"]\n",
    "                ],\n",
    "            }\n",
    "            serializable.append(ser_result)\n",
    "        summary = {\n",
    "            \"total_frames\": results[\"total_frames\"],\n",
    "            \"successful_frames\": results.get(\"successful_frames\", 0),\n",
    "            \"total_matches\": results[\"total_matches\"],\n",
    "            \"unique_players\": results[\"unique_players\"],\n",
    "            \"processing_time\": results.get(\"processing_time\", 0),\n",
    "            \"avg_matches_per_frame\": results[\"total_matches\"]\n",
    "            / max(1, results[\"total_frames\"]),\n",
    "            \"success_rate\": results.get(\"successful_frames\", 0)\n",
    "            / max(1, results[\"total_frames\"]),\n",
    "        }\n",
    "        output_data = {\"summary\": summary, \"frame_results\": serializable}\n",
    "        with open(json_path, \"w\") as f:\n",
    "            json.dump(output_data, f, indent=2)\n",
    "\n",
    "        print(f\"Results saved successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19ca30",
   "metadata": {},
   "source": [
    "## Sample results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad534f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_results(results: Dict, num_samples: int = 5):\n",
    "    try:\n",
    "        print(f\"\\n sample results\")\n",
    "        frames_with_matches = [r for r in results[\"results\"] if r[\"num_matches\"] > 0]\n",
    "        if not frames_with_matches:\n",
    "            print(\"No frames with matches found!\")\n",
    "            return\n",
    "        step = max(1, len(frames_with_matches) // num_samples)\n",
    "        sample_frames = frames_with_matches[::step][:num_samples]\n",
    "        print(f\"Sample frames with matches: {[f['frame_id'] for f in sample_frames]}\")\n",
    "\n",
    "        for frame_result in sample_frames:\n",
    "            print(f\"\\n Frame {frame_result['frame_id']}\")\n",
    "            print(f\"Matches: {frame_result['num_matches']}\")\n",
    "            tac_ids = [\n",
    "                det.player_id\n",
    "                for det in frame_result[\"tacticam_detections\"]\n",
    "                if det.player_id\n",
    "            ]\n",
    "            broad_ids = [\n",
    "                det.player_id\n",
    "                for det in frame_result[\"broadcast_detections\"]\n",
    "                if det.player_id\n",
    "            ]\n",
    "            print(f\"Tacticam player IDs: {tac_ids}\")\n",
    "            print(f\"Broadcast player IDs: {broad_ids}\")\n",
    "            for match in frame_result[\"matches\"]:\n",
    "                print(\n",
    "                    f\"  Match: Tac_ID={match.tacticam_id} ↔ Broad_ID={match.broadcast_id} (similarity: {match.similarity_score:.3f})\"\n",
    "                )\n",
    "    except Exception as e:\n",
    "        print(f\"Error showing sample results: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9bb346",
   "metadata": {},
   "source": [
    "## Uploading videos for reidentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ed232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_videos():\n",
    "    print(\"Please upload your video files:\")\n",
    "    uploaded = files.upload()\n",
    "    video_files = []\n",
    "    for filename in uploaded.keys():\n",
    "        if filename.lower().endswith((\".mp4\", \".avi\", \".mov\", \".mkv\")):\n",
    "            video_files.append(filename)\n",
    "            print(f\"Uploaded: {filename}\")\n",
    "    if len(video_files) < 2:\n",
    "        print(\"Please upload at least 2 video files\")\n",
    "        return None, None\n",
    "    return video_files[0], video_files[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7755b",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd44a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_colab(\n",
    "    tac_video_path: str,\n",
    "    broad_video_path: str,\n",
    "    output_video_path: str = None,\n",
    "    max_frames: int = 200,\n",
    "):\n",
    "    try:\n",
    "        reid_system = PlayerReIDSystem(\"yolov8n.pt\")\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to initialize system: {e}\")\n",
    "        return None\n",
    "    try:\n",
    "        results = reid_system.process_videos(\n",
    "            tac_video_path, broad_video_path, output_video_path, max_frames\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Video processing failed: {e}\")\n",
    "        return None\n",
    "    save_results(results)\n",
    "    print(f\"Total frames processed: {results['total_frames']}\")\n",
    "    print(f\"Frames with matches: {results.get('successful_frames', 0)}\")\n",
    "    print(f\"Total matches made: {results['total_matches']}\")\n",
    "    print(f\"Unique players identified: {results['unique_players']}\")\n",
    "    print(f\"Processing time: {results.get('processing_time', 0):.1f} seconds\")\n",
    "    if results[\"total_frames\"] > 0:\n",
    "        avg_matches = results[\"total_matches\"] / results[\"total_frames\"]\n",
    "        success_rate = results.get(\"successful_frames\", 0) / results[\"total_frames\"]\n",
    "        print(f\"Average matches per frame: {avg_matches:.2f}\")\n",
    "        print(f\"Success rate: {success_rate:.2%}\")\n",
    "    if output_video_path:\n",
    "        print(f\"\\nOutput video: {output_video_path}\")\n",
    "    print(\"Detailed results saved to: results.json\")\n",
    "    show_sample_results(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e06419c",
   "metadata": {},
   "source": [
    "## Debug frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71953e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_single_frame(tac_video_path: str, broad_video_path: str, frame_num: int = 50):\n",
    "    print(f\"Debug analysis for frame {frame_num}\")\n",
    "    try:\n",
    "        reid_system = PlayerReIDSystem(\"yolov8n.pt\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize system: {e}\")\n",
    "        return None\n",
    "    tac_cap = cv2.VideoCapture(tac_video_path)\n",
    "    broad_cap = cv2.VideoCapture(broad_video_path)\n",
    "    tac_cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    broad_cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret1, tac_frame = tac_cap.read()\n",
    "    ret2, broad_frame = broad_cap.read()\n",
    "    if not ret1 or not ret2:\n",
    "        print(\"Could not read frames\")\n",
    "        return None\n",
    "    result = reid_system.process_frame_pair(tac_frame, broad_frame, frame_num)\n",
    "    print(f\"\\n Frame {frame_num} Analysis:\")\n",
    "    print(f\"Tacticam detections: {len(result['tacticam_detections'])}\")\n",
    "    print(f\"Broadcast detections: {len(result['broadcast_detections'])}\")\n",
    "    print(f\"Cross-camera matches: {result['num_matches']}\")\n",
    "    print(\"\\n Tacticam Detections:\")\n",
    "    for i, det in enumerate(result[\"tacticam_detections\"]):\n",
    "        print(\n",
    "            f\"  {i}: ID={det.player_id}, TrackID={det.track_id}, Conf={det.confidence:.3f}, BBox={det.bbox}\"\n",
    "        )\n",
    "    print(\"\\n Broadcast Detections:\")\n",
    "    for i, det in enumerate(result[\"broadcast_detections\"]):\n",
    "        print(\n",
    "            f\"  {i}: ID={det.player_id}, TrackID={det.track_id}, Conf={det.confidence:.3f}, BBox={det.bbox}\"\n",
    "        )\n",
    "    print(\"\\n Matches:\")\n",
    "    for match in result[\"matches\"]:\n",
    "        print(\n",
    "            f\"Tac[{match.tacticam_idx}] ↔ Broad[{match.broadcast_idx}]: \"\n",
    "            f\"IDs {match.tacticam_id}↔{match.broadcast_id}, similarity={match.similarity_score:.3f}\"\n",
    "        )\n",
    "    tac_vis, broad_vis = reid_system.visualize_results(tac_frame, broad_frame, result)\n",
    "    cv2.imwrite(f\"debug_frame_{frame_num}_tacticam.jpg\", tac_vis)\n",
    "    cv2.imwrite(f\"debug_frame_{frame_num}_broadcast.jpg\", broad_vis)\n",
    "    print(\n",
    "        f\"\\n Debug images saved: debug_frame_{frame_num}_tacticam.jpg, debug_frame_{frame_num}_broadcast.jpg\"\n",
    "    )\n",
    "    tac_cap.release()\n",
    "    broad_cap.release()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tac_video, broad_video = upload_videos()\n",
    "if tac_video and broad_video:\n",
    "    results = main_colab(tac_video, broad_video, \"output.mp4\", 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
